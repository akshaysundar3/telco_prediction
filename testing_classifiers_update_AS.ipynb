{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Approach Taken in Modelling\n",
    "\n",
    "After the data exploration and preprocessing parts, we've looked into finding a model that predicts a customer's tendency to not renew a contract (churn) sufficiently well. For this we have tested multiple classification models (various methods along with tuning hyperparameters based on classification error), and finally chosen one based on a list of criteria. \n",
    "\n",
    "The training was conducted on 60% of the data, and testing was ultimately done to generate scores on the remaining 40% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Warning Blocker \n",
    "\n",
    "An initial blocker function was defined to block unnecessary warnings on the models. This is after the models were checked for any potential issues, to clean up the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, log_loss, auc\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Two data sets were previously created with a split based on training and final testing. Both are loaded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"telco_train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"telco_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Engineering\n",
    "\n",
    "A few additional columns are added, that might assist the model in predicting the churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>senior</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phone</th>\n",
       "      <th>multiple_lines</th>\n",
       "      <th>online_security</th>\n",
       "      <th>online_backup</th>\n",
       "      <th>device_protection</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>internet_dsl</th>\n",
       "      <th>internet_fiber</th>\n",
       "      <th>contract_1_yr</th>\n",
       "      <th>contract_2_yr</th>\n",
       "      <th>payment_credit_card</th>\n",
       "      <th>payment_electronic_check</th>\n",
       "      <th>payment_mailed_check</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.85</td>\n",
       "      <td>1336.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.20</td>\n",
       "      <td>5129.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.45</td>\n",
       "      <td>23.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.20</td>\n",
       "      <td>237.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.55</td>\n",
       "      <td>521.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.95</td>\n",
       "      <td>613.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.80</td>\n",
       "      <td>1414.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6791</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.65</td>\n",
       "      <td>733.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.95</td>\n",
       "      <td>219.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  senior  partner  dependents  tenure  phone  multiple_lines  \\\n",
       "2142       0       0        0           1      21      1               0   \n",
       "1623       0       0        0           0      54      1               1   \n",
       "6074       1       0        1           0       1      0               0   \n",
       "1362       1       0        0           0       4      1               0   \n",
       "6754       1       0        0           1       0      1               1   \n",
       "1212       1       0        0           0       7      1               0   \n",
       "2722       1       0        1           1      32      1               0   \n",
       "4006       1       0        1           1      72      1               0   \n",
       "6791       1       0        0           0      19      0               0   \n",
       "5466       1       0        0           1      10      1               0   \n",
       "\n",
       "      online_security  online_backup  device_protection  ...    \\\n",
       "2142                1              0                  1  ...     \n",
       "1623                0              1                  0  ...     \n",
       "6074                0              0                  0  ...     \n",
       "1362                0              0                  0  ...     \n",
       "6754                1              1                  0  ...     \n",
       "1212                0              0                  0  ...     \n",
       "2722                0              0                  0  ...     \n",
       "4006                0              0                  0  ...     \n",
       "6791                0              0                  1  ...     \n",
       "5466                0              0                  0  ...     \n",
       "\n",
       "      monthly_charges  total_charges  internet_dsl  internet_fiber  \\\n",
       "2142            64.85        1336.80             1               0   \n",
       "1623            97.20        5129.45             0               1   \n",
       "6074            23.45          23.45             1               0   \n",
       "1362            70.20         237.95             0               1   \n",
       "6754            61.90           0.00             1               0   \n",
       "1212            69.55         521.35             0               1   \n",
       "2722            18.95         613.95             0               0   \n",
       "4006            19.80        1414.65             0               0   \n",
       "6791            39.65         733.35             1               0   \n",
       "5466            19.95         219.50             0               0   \n",
       "\n",
       "      contract_1_yr  contract_2_yr  payment_credit_card  \\\n",
       "2142              1              0                    0   \n",
       "1623              0              1                    0   \n",
       "6074              0              0                    0   \n",
       "1362              0              0                    0   \n",
       "6754              0              1                    0   \n",
       "1212              0              0                    0   \n",
       "2722              0              1                    0   \n",
       "4006              0              1                    1   \n",
       "6791              0              0                    0   \n",
       "5466              1              0                    0   \n",
       "\n",
       "      payment_electronic_check  payment_mailed_check  churn  \n",
       "2142                         0                     1      0  \n",
       "1623                         0                     0      0  \n",
       "6074                         1                     0      1  \n",
       "1362                         1                     0      1  \n",
       "6754                         0                     0      0  \n",
       "1212                         1                     0      0  \n",
       "2722                         0                     1      0  \n",
       "4006                         0                     0      0  \n",
       "6791                         1                     0      1  \n",
       "5466                         0                     0      0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'senior', 'partner', 'dependents', 'tenure', 'phone',\n",
       "       'multiple_lines', 'online_security', 'online_backup',\n",
       "       'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies',\n",
       "       'paperless_billing', 'monthly_charges', 'total_charges', 'internet_dsl',\n",
       "       'internet_fiber', 'contract_1_yr', 'contract_2_yr',\n",
       "       'payment_credit_card', 'payment_electronic_check',\n",
       "       'payment_mailed_check', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Feature for average charges by tenure\n",
    "df[\"average_charges\"] = df.apply(lambda x: 0.0 if int(x[\"tenure\"])==0 else x[\"total_charges\"]/float(x[\"tenure\"]), axis=1)\n",
    "df_test[\"average_charges\"] = df_test.apply(lambda x: 0.0 if int(x[\"tenure\"])==0 else x[\"total_charges\"]/float(x[\"tenure\"]), axis=1)\n",
    "\n",
    "# Adding Feature for whether the customer is a single parent\n",
    "df[\"single_parent\"] = df.apply(lambda x: 1 if (int(x['partner'])==0 and int(x['dependents'])!=0) else 0, axis=1)\n",
    "df_test[\"single_parent\"] = df_test.apply(lambda x: 1 if (int(x['partner'])==0 and int(x['dependents'])!=0) else 0, axis=1)\n",
    "\n",
    "# Adding Feature for whether the customer is a senior without immediate family\n",
    "df[\"lonely_senior\"] = df.apply(lambda x: 1 if (int(x['partner'])==0 and int(x['dependents'])==0 and int(x['senior'])==1) else 0, axis=1)\n",
    "df_test[\"lonely_senior\"] = df_test.apply(lambda x: 1 if (int(x['partner'])==0 and int(x['dependents'])==0 and int(x['senior'])==1) else 0, axis=1)\n",
    "\n",
    "# Adding Feature for whether the customer is a repeat renewer (has renewed monthly for over 12 months)\n",
    "df[\"repeat_renewer\"] = df.apply(lambda x: 1 if (int(x['tenure'])>12 and int(x['contract_1_yr'])==0 and int(x['contract_2_yr'])==0) else 0, axis=1)\n",
    "df_test[\"repeat_renewer\"] = df_test.apply(lambda x: 1 if (int(x['tenure'])>12 and int(x['contract_1_yr'])==0 and int(x['contract_2_yr'])==0) else 0, axis=1)\n",
    "\n",
    "# Adding Feature for total count of family members for the customer, using and sharing services\n",
    "df[\"total_fam\"] = df.apply(lambda x: int(x['partner']) + int(x['dependents']) + 1, axis=1)\n",
    "df_test[\"total_fam\"] = df_test.apply(lambda x: int(x['partner']) + int(x['dependents']) + 1, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 5 additional variables added to improve prediction are -\n",
    "\n",
    "Average Charges - This variable indicates the total charges incurred by the customer divided by the tenure. This captures the prior payments made in different contract types (prior payments on a monthly basis would be captured to be higher than those made in a yearly basis)\n",
    "\n",
    "Single Parent - This is to specifically segment out single parents, with dependents but no partner. We believe this might have an impact on the prediction\n",
    "\n",
    "Lonely Senior - Similar to the previous variable, this is to segment out seniors who have no partner or dependents, added for potential segmentation of customers\n",
    "\n",
    "Repeat Renewer - This captures customers who renew on a monthly basis and have a tenure of more than 12 months. It could indicate a customer who is willing to leave the plan on a short notice.\n",
    "\n",
    "Total Family - The total count of family members represented by the customer, including themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the Datasets to Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"churn\"], axis=1)\n",
    "y = df.churn.reset_index().churn\n",
    "\n",
    "X_test = df_test.drop([\"churn\"], axis=1)\n",
    "y_test = df_test.churn.reset_index().churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "Xu = X.values\n",
    "Xu_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Dataset\n",
    "\n",
    "Scaling the dataset adjusts for variables in the data being very different in the range of values. By scaling or normalization, this brings the relative magnitudes to be the same across all features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for Cross Validation\n",
    "\n",
    "Cross Validation will be used in all models to determine the cross-validation error and other metrics, which will be a proxy for the generalization error on real life data. The selection of hyper-parameters specific to each model will be based on this cross-validation error. Since there will be a tendency of the model to overfit on the training data, the metrics calculated by cross validation will better assess the model performance on external data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of Null Accuracy\n",
    "\n",
    "Prior to Running models, we can set a baseline by calculating the null accuracy. Every model must perform better than simply guessing based on the value that appears more frequently in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Null Accuracy of Churn Prediction: 0.734\n"
     ]
    }
   ],
   "source": [
    "print(\"The Null Accuracy of Churn Prediction: %0.3f\" % (1-np.mean(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the null accuracy in the training data is 0.734, therefore every model must perform better than this accuracy. Since the null accuracy is so high, the data is taken to be skewed, and other metrics like the F1 score and the ROC-AUC score have to be taken into account for model assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Model Assessment\n",
    "\n",
    "#### Prediction Accuracy - We will be using the prediction accuracy as one of the central metrics to assess models. This will simply be computed as the fraction of observations correctly classified by the algorithm. However, since the data is skewed and the null accuracy is observed to be so high, the classifier will have to do much better than this. If the results of the models aren't a stark improvement on the null accuracy, we will have to depend on other metrics to evaluate the performance of our models.\n",
    "\n",
    "#### F1 Score - The F1 score is the weighted average of the precision and the recall. The precision of a classifier is the ratio of correctly predicted positive observations vs the total predicted positive observations, and the recall is the ratio of correctly predicted positive observations to all true positive observations. This basically assesses how well the model is working with the churn with respect to which we have calculated the precision and recall.\n",
    "\n",
    "#### ROC AUC Score - The area under the curve of the receiver operator charateristic plot of the model is taken into account as a good indicator of the model's performance, even in the case of the data being skewed in one direction. While this skew affects the accuracy of the class prediction, the ROC AUC score will still be a valid metric. \n",
    "\n",
    "#### Given the three metrics we have just seen, we will make our tuning on the basis of accuracy, but the final decision on the model will be made by looking at all three scores, and weighing the F1 and ROC-AUC score with higher priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Logistic Regression\n",
    "\n",
    "First step involves looking at the performance of a simple logistic regression classifier. This is a stepping stone to moving to penalized models, to reduce the risk of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression on training set: 0.803\n",
      "Cross-Validation Score is 0.799\n",
      "F1 Score is 0.571\n",
      "ROC-AUC Score is 0.706\n"
     ]
    }
   ],
   "source": [
    "logreg_basic = LogisticRegression(solver=\"lbfgs\", random_state=0)\n",
    "logreg_basic.fit(X, y)\n",
    "print(\"Accuracy of Logistic Regression on training set: {:.3f}\".format(logreg_basic.score(X, y)))\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_lrb = list()\n",
    "f1_lrb = list()\n",
    "ra_lrb = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    logreg_basic_gen = LogisticRegression(solver=\"lbfgs\", random_state=0)\n",
    "    logreg_basic_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_lrb.append(logreg_basic_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = logreg_basic_gen.predict(X[test_index])\n",
    "    f1_lrb.append(f1_score(y[test_index],y_pred))\n",
    "    ra_lrb.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross-Validation Score is %0.3f\" % np.mean(gen_error_lrb))\n",
    "print(\"F1 Score is %0.3f\" % np.mean(f1_lrb))\n",
    "print(\"ROC-AUC Score is %0.3f\" % np.mean(ra_lrb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not bad in terms of cross validation error. We will look further at the penalized versions of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Logistic Regression\n",
    "\n",
    "Ridge regression will contain the l2 penalty, reducing the magnitude of the parameters of each of the features, hereby reducing their influence on the model. This plays a role in reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Ridge Logistic Regression on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "logreg_ridge = LogisticRegression(solver=\"lbfgs\", random_state=0, penalty=\"l2\")\n",
    "logreg_ridge.fit(X, y)\n",
    "print(\"Accuracy of Ridge Logistic Regression on training set: {:.2f}\".format(logreg_ridge.score(X, y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the penalization hyper-parameter involved with the magnitude of decrease of the betas is set to a default value of 1. We will aim to tune it on the basis of 10 fold cross validation, tuned to maximize accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Regression Parameter is: 0.08\n",
      "Cross-Validation Score is 0.801\n",
      "F1 Score is 0.573\n",
      "ROC-AUC Score is 0.707\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Estimating Ridge Parameter\n",
    "\n",
    "best_c_ridge = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(1,101):\n",
    "    c = (i/100)\n",
    "    score_list = list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        temp_model = LogisticRegression(solver=\"lbfgs\", random_state=0, penalty=\"l2\", C=c)\n",
    "        temp_model.fit(X[train_index], y[train_index])\n",
    "        score_list.append(temp_model.score(X[test_index], y[test_index]))\n",
    "    \n",
    "    if np.mean(score_list)>best_score:\n",
    "        best_score=np.mean(score_list)\n",
    "        best_c_ridge=c\n",
    "\n",
    "print(\"Best Ridge Regression Parameter is: %0.2f\" % best_c_ridge)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_lrr = list()\n",
    "f1_lrr = list()\n",
    "ra_lrr = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    logreg_ridge_gen = LogisticRegression(solver=\"lbfgs\", random_state=0, penalty=\"l2\", C=best_c_ridge)\n",
    "    logreg_ridge_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_lrr.append(logreg_ridge_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = logreg_ridge_gen.predict(X[test_index])\n",
    "    f1_lrr.append(f1_score(y[test_index],y_pred))\n",
    "    ra_lrr.append(roc_auc_score(y[test_index],y_pred))\n",
    "\n",
    "print(\"Cross-Validation Score is %0.3f\" % np.mean(gen_error_lrr))\n",
    "print(\"F1 Score is %0.3f\" % np.mean(f1_lrr))\n",
    "print(\"ROC-AUC Score is %0.3f\" % np.mean(ra_lrr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear improvement in all scores in comparison to the simple logisic regression. To further analyze the best regression based model, we will look at the l1 penalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Logistic Regression\n",
    "\n",
    "Lasso logistic regression contains the l1 penalization, which essentially drops features that have lesser influence on the model. The number of these features removed is determined by the hyper parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Lasso Logistic Regression on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "logreg_lasso = LogisticRegression(solver='saga', random_state=0, penalty=\"l1\")\n",
    "logreg_lasso.fit(X, y)\n",
    "print(\"Accuracy of Lasso Logistic Regression on training set: {:.2f}\".format(logreg_lasso.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy will be computed by cross validation as done for Ridge, and the hyper parameter will be tuned to maximize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso Regression Parameter is: 0.07\n",
      "Cross-Validation Score is 0.801\n",
      "F1 Score is 0.572\n",
      "ROC-AUC Score is 0.707\n"
     ]
    }
   ],
   "source": [
    "# Estimating Lasso Parameter\n",
    "\n",
    "best_c_lasso = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(1,101):\n",
    "    c = (i/100)\n",
    "    score_list = list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        temp_model = LogisticRegression(solver=\"saga\", random_state=0, penalty=\"l1\", C=c)\n",
    "        temp_model.fit(X[train_index], y[train_index])\n",
    "        score_list.append(temp_model.score(X[test_index], y[test_index]))\n",
    "    \n",
    "    if np.mean(score_list)>best_score:\n",
    "        best_score=np.mean(score_list)\n",
    "        best_c_lasso=c\n",
    "\n",
    "print(\"Best Lasso Regression Parameter is: %0.2f\" % best_c_lasso)\n",
    "\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_lrl = list()\n",
    "f1_lrl = list()\n",
    "ra_lrl = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    logreg_lasso_gen = LogisticRegression(solver=\"saga\", random_state=0, penalty=\"l2\", C=best_c_lasso)\n",
    "    logreg_lasso_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_lrl.append(logreg_lasso_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = logreg_lasso_gen.predict(X[test_index])\n",
    "    f1_lrl.append(f1_score(y[test_index],y_pred))\n",
    "    ra_lrl.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross-Validation Score is %0.3f\" % np.mean(gen_error_lrl))\n",
    "print(\"F1 Score is %0.3f\" % np.mean(f1_lrl))\n",
    "print(\"ROC-AUC Score is %0.3f\" % np.mean(ra_lrl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are comparable to Ridge. We will look at other possible models to analyze their performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant analyses\n",
    "\n",
    "Discriminant analyses, the LDA and QDA, will be used on the data. This involves projection based classification. The dimension between the two classes with the most variance is used as the projection dimension, and the classification is done on an orthogonal division of this dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA  \n",
    "\n",
    "The Linear Discriminant Analysis takes into account that the two classes have the same variance in terms of the normal distribution. This will not be appropriate to use in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA on training set: 0.80\n",
      "Cross Validation Score on LDA:  0.7988958593149669\n",
      "F1 score on LDA:  0.5710837633952383\n",
      "ROC-AUC Score on LDA:  0.7060737173292818\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X, y)\n",
    "print(\"Accuracy of LDA on training set: {:.2f}\".format(lda.score(X, y)))\n",
    "\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_lda = list()\n",
    "f1_lda = list()\n",
    "ra_lda = list()\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    lda_gen = LinearDiscriminantAnalysis()\n",
    "    lda_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_lda.append(lda_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = lda_gen.predict(X[test_index])\n",
    "    f1_lda.append(f1_score(y[test_index],y_pred))\n",
    "    ra_lda.append(roc_auc_score(y[test_index],y_pred))\n",
    "\n",
    "print(\"Cross Validation Score on LDA: \",np.mean(gen_error_lda))\n",
    "print(\"F1 score on LDA: \",np.mean(f1_lda))\n",
    "print(\"ROC-AUC Score on LDA: \",np.mean(ra_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QDA\n",
    "\n",
    "The quadratic discriminant analysis applies to a more general case, as it needs no assumption on the basis of the covariance of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of QDA on traning set: 0.74\n",
      "Cross Validation Score on QDA:  0.7273666906012624\n",
      "F1 Score on QDA:  0.6052680690279306\n",
      "ROC-AUC Score on QDA:  0.7477866698745134\n"
     ]
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X, y)\n",
    "print(\"Accuracy of QDA on traning set: {:.2f}\".format(qda.score(X, y)))\n",
    "\n",
    "# Cross Validation Accuracy\n",
    "\n",
    "gen_error_qda = list()\n",
    "f1_qda = list()\n",
    "ra_qda = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    qda_gen = QuadraticDiscriminantAnalysis()\n",
    "    qda_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_qda.append(qda_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = qda_gen.predict(X[test_index])\n",
    "    f1_qda.append(f1_score(y[test_index],y_pred))\n",
    "    ra_qda.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on QDA: \",np.mean(gen_error_qda))\n",
    "print(\"F1 Score on QDA: \",np.mean(f1_qda))\n",
    "print(\"ROC-AUC Score on QDA: \",np.mean(ra_qda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy involved in the QDA algorithm is considerably lower than regression models, but the F1 score and AUC score are higher. We will tune the QDA by including a regularization parameter, using 10 fold cross validation as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization parameter for QDA: 0.81\n",
      "Cross Validation Score on QDA:  0.7738675157149515\n",
      "F1 Score on QDA:  0.6031140044398728\n",
      "ROC-AUC Score on QDA:  0.7342575950730985\n"
     ]
    }
   ],
   "source": [
    "# Estimating QDA regularization Parameter\n",
    "\n",
    "best_c_qda = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(1,101):\n",
    "    c = (i/100)\n",
    "    score_list = list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        temp_model = QuadraticDiscriminantAnalysis(reg_param=c)\n",
    "        temp_model.fit(X[train_index], y[train_index])\n",
    "        score_list.append(temp_model.score(X[test_index], y[test_index]))\n",
    "    \n",
    "    if np.mean(score_list)>best_score:\n",
    "        best_score=np.mean(score_list)\n",
    "        best_c_qda=c\n",
    "\n",
    "print(\"Best regularization parameter for QDA: %0.2f\" % best_c_qda)\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_qda = list()\n",
    "f1_qda = list()\n",
    "ra_qda = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    qda_gen = QuadraticDiscriminantAnalysis(reg_param=best_c_qda)\n",
    "    qda_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_qda.append(qda_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = qda_gen.predict(X[test_index])\n",
    "    f1_qda.append(f1_score(y[test_index],y_pred))\n",
    "    ra_qda.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on QDA: \",np.mean(gen_error_qda))\n",
    "print(\"F1 Score on QDA: \",np.mean(f1_qda))\n",
    "print(\"ROC-AUC Score on QDA: \",np.mean(ra_qda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is not much lower than the regression models, however the F1 and AUC scores are considerably better. The QDA model is a strong contender for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "The k-nearest neighbour is a non parametric classification algorithm, where points are assigned to the nearest cluster iteratively, and hereby classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.83\n",
      "Cross Validation Score on K Nearest Neighbour:  0.7536333345930489\n",
      "F1 Score on K Nearest Neighbour:  0.5193314995324623\n",
      "ROC-AUC Score on K Nearest Neighbour:  0.6738763822146923\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X, y)\n",
    "\n",
    "print(\"Accuracy of KNN classifier on training set: {:.2f}\".format(knn.score(X, y)))\n",
    "\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "gen_error_knn = list()\n",
    "f1_knn = list()\n",
    "ra_knn = list()\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    knn_gen = KNeighborsClassifier()\n",
    "    knn_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_knn.append(knn_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = knn_gen.predict(X[test_index])\n",
    "    f1_knn.append(f1_score(y[test_index],y_pred))\n",
    "    ra_knn.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on K Nearest Neighbour: \",np.mean(gen_error_knn))\n",
    "print(\"F1 Score on K Nearest Neighbour: \",np.mean(f1_knn))\n",
    "print(\"ROC-AUC Score on K Nearest Neighbour: \",np.mean(ra_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes is a probabilistic classification algorithms relying on Bayes theorem of prior probabilities. This assumes strong independence between features, and is hence not the most appropriate model to apply here on the basis of the observed multi-colinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GNB classifier on training set: 0.75\n",
      "Cross Validation Score on Gaussian Naive Bayes:  0.7479567413677992\n",
      "F1 Score on Gaussian Naive Bayes:  0.5964259759775136\n",
      "ROC-AUC Score on Gaussian Naive Bayes:  0.734051159422828\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB().fit(X, y)\n",
    "\n",
    "print(\"Accuracy of GNB classifier on training set: {:.2f}\".format(gnb.score(X, y)))\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_gnb = list()\n",
    "f1_gnb = list()\n",
    "ra_gnb = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    gnb_gen = GaussianNB()\n",
    "    gnb_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_gnb.append(gnb_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = gnb_gen.predict(X[test_index])\n",
    "    f1_gnb.append(f1_score(y[test_index],y_pred))\n",
    "    ra_gnb.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on Gaussian Naive Bayes: \",np.mean(gen_error_gnb))\n",
    "print(\"F1 Score on Gaussian Naive Bayes: \",np.mean(f1_gnb))\n",
    "print(\"ROC-AUC Score on Gaussian Naive Bayes: \",np.mean(ra_gnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Support Vector Machines are a classification algorithm that tries to separate the two categories by as large a margin as possible. In the case of non separability (as is this case) the soft SVM attempts to create a decision boundary that rightly classifies as many points as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.82\n",
      "Cross Validation Score on Support Vector Machine:  0.7949932605217742\n",
      "F1 Score on Support Vector Machine:  0.544760232353444\n",
      "ROC-AUC Score on Support Vector Machine:  0.6897575170256924\n"
     ]
    }
   ],
   "source": [
    "svm = SVC().fit(X, y)\n",
    "\n",
    "print(\"Accuracy of SVM classifier on training set: {:.2f}\".format(svm.score(X, y)))\n",
    "\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_svm = list()\n",
    "f1_svm = list()\n",
    "ra_svm = list()\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    svm_gen = SVC()\n",
    "    svm_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_svm.append(svm_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = svm_gen.predict(X[test_index])\n",
    "    f1_svm.append(f1_score(y[test_index],y_pred))\n",
    "    ra_svm.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on Support Vector Machine: \",np.mean(gen_error_svm))\n",
    "print(\"F1 Score on Support Vector Machine: \",np.mean(f1_svm))\n",
    "print(\"ROC-AUC Score on Support Vector Machine: \",np.mean(ra_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "Random Forests are an enseble method that apply the concept of combining multiple decision trees together and using them to classify observations. When predicting, the result with most \"votes\" from the individual trees will be the classification of the random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forests classifier on training set: 0.98\n",
      "Cross Validation Score on Random Forests:  0.776357028582946\n",
      "F1 Score on Random Forests:  0.5949697597339095\n",
      "ROC AUC Score on Random Forests:  0.7190032968126114\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X, y)\n",
    "\n",
    "print(\"Accuracy of Random Forests classifier on training set: {:.2f}\".format(rfc.score(X, y)))\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "gen_error_rf = list()\n",
    "f1_rf = list()\n",
    "ra_rf = list()\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    rf_gen = RandomForestClassifier()\n",
    "    rf_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_rf.append(rf_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = svm_gen.predict(X[test_index])\n",
    "    f1_rf.append(f1_score(y[test_index],y_pred))\n",
    "    ra_rf.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on Random Forests: \",np.mean(gen_error_rf))\n",
    "print(\"F1 Score on Random Forests: \",np.mean(f1_rf))\n",
    "print(\"ROC AUC Score on Random Forests: \",np.mean(ra_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron\n",
    "\n",
    "The Multi Layer Perceptron is a feedforward artificial neural network. MLP utilizes the supervised learning technique of backpropagation for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP classifier on training set: 0.81\n",
      "Cross Validation Score on NN: 0.798\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(alpha=1)\n",
    "mlp.fit(X, y)\n",
    "\n",
    "print(\"Accuracy of MLP classifier on training set: {:.2f}\".format(mlp.score(X, y)))\n",
    "\n",
    "\n",
    "# Cross Validation Score\n",
    "\n",
    "gen_error_nn = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    nn_gen = MLPClassifier(alpha=1)\n",
    "    nn_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_nn.append(nn_gen.score(X[test_index], y[test_index]))\n",
    "    \n",
    "print(\"Cross Validation Score on NN: %0.3f\" % np.mean(gen_error_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Regularization Hyperparameter of Neural Net to Maximise Crossvalidation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter for MLP: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Estimating Hyper-Parameter\n",
    "\n",
    "best_alpha = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(1,6):\n",
    "    c = (i/5)\n",
    "    score_list = list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        temp_model = MLPClassifier(alpha=c)\n",
    "        temp_model.fit(X[train_index], y[train_index])\n",
    "        score_list.append(temp_model.score(X[test_index], y[test_index]))\n",
    "    \n",
    "    if np.mean(score_list)>best_score:\n",
    "        best_score=np.mean(score_list)\n",
    "        best_alpha=c\n",
    "\n",
    "print(\"Best Parameter for MLP: %0.3f\" % best_alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of the Crossvalidation score of the best regularized MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score on MLP with tuned Hyperparameter:  0.7944585112681557\n",
      "F1 Score on MLP with tuned Hyperparameter:  0.5592859792659995\n",
      "ROC-AUC Score on MLP with tuned Hyperparameter:  0.6986585556727024\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "\n",
    "gen_error_nn = list()\n",
    "f1_nn = list()\n",
    "ra_nn = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    nn_gen = MLPClassifier(alpha=best_alpha)\n",
    "    nn_gen.fit(X[train_index], y[train_index])\n",
    "    gen_error_nn.append(nn_gen.score(X[test_index], y[test_index]))\n",
    "    y_pred = nn_gen.predict(X[test_index])\n",
    "    f1_nn.append(f1_score(y[test_index],y_pred))\n",
    "    ra_nn.append(roc_auc_score(y[test_index],y_pred))\n",
    "    \n",
    "print(\"Cross Validation Score on MLP with tuned Hyperparameter: \",np.mean(gen_error_nn))\n",
    "print(\"F1 Score on MLP with tuned Hyperparameter: \",np.mean(f1_nn))\n",
    "print(\"ROC-AUC Score on MLP with tuned Hyperparameter: \",np.mean(ra_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Model Performances\n",
    "\n",
    "Now that we have calculated the scores corresponding to each of the models with our data, we can draw comparisons between them. We will look at three main metrics, the accuracy of prediction, the F1 score and the Receiver Operator Characteristic Area under curve score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.7994290339241401\n",
      "Ridge Regression:  0.8012030283561972\n",
      "Lasso Regression:  0.8010254084627692\n",
      "LDA:  0.7988958593149669\n",
      "QDA:  0.7738675157149515\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gen_error_dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a22b42ce153d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LDA: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_error_lda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"QDA: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_error_qda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decision Tree: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_error_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K Nearest Neighbour: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_error_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaussian Naive Bayes: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_error_gnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_error_dt' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \",np.mean(gen_error_lrb))\n",
    "print(\"Ridge Regression: \",np.mean(gen_error_lrr))\n",
    "print(\"Lasso Regression: \",np.mean(gen_error_lrl))\n",
    "print(\"LDA: \",np.mean(gen_error_lda))\n",
    "print(\"QDA: \",np.mean(gen_error_qda))\n",
    "print(\"Decision Tree: \",np.mean(gen_error_dt))\n",
    "print(\"K Nearest Neighbour: \",np.mean(gen_error_knn))\n",
    "print(\"Gaussian Naive Bayes: \",np.mean(gen_error_gnb))\n",
    "print(\"SVM: \",np.mean(gen_error_svm))\n",
    "print(\"Random Forests: \",np.mean(gen_error_rf))\n",
    "print(\"MLP: \",np.mean(gen_error_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression: %0.3f\" % np.mean(f1_lrb))\n",
    "print(\"Ridge Regression: %0.3f\" % np.mean(f1_lrr))\n",
    "print(\"Lasso Regression: %0.3f\" % np.mean(f1_lrl))\n",
    "print(\"LDA: %0.3f\" % np.mean(f1_lda))\n",
    "print(\"QDA: %0.3f\" % np.mean(f1_qda))\n",
    "print(\"K Nearest Neighbour: %0.3f\" % np.mean(f1_knn))\n",
    "print(\"Gaussian Naive Bayes: %0.3f\" % np.mean(f1_gnb))\n",
    "print(\"SVM: %0.3f\" % np.mean(f1_svm))\n",
    "print(\"Random Forests: %0.3f\" % np.mean(f1_rf))\n",
    "print(\"MLP: %0.3f\" % np.mean(f1_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression: %0.3f\" % np.mean(ra_lrb))\n",
    "print(\"Ridge Regression: %0.3f\" % np.mean(ra_lrr))\n",
    "print(\"Lasso Regression: %0.3f\" % np.mean(ra_lrl))\n",
    "print(\"LDA: %0.3f\" % np.mean(ra_lda))\n",
    "print(\"QDA: %0.3f\" % np.mean(ra_qda))\n",
    "print(\"K Nearest Neighbour: %0.3f\" % np.mean(ra_knn))\n",
    "print(\"Gaussian Naive Bayes: %0.3f\" % np.mean(ra_gnb))\n",
    "print(\"SVM: %0.3f\" % np.mean(ra_svm))\n",
    "print(\"Random Forests: %0.3f\" % np.mean(ra_rf))\n",
    "print(\"MLP: %0.3f\" % np.mean(ra_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulated View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\"Logistic Regression\",\"Ridge Regression\",\"Lasso Regression\",\"Linear Discriminant Analysis\",\n",
    "               \"Quadratic Discriminant Analysis\",\"K Nearest Neighbour\",\"Gaussian Naive Bayes\",\n",
    "               \"Support Vector Machine\",\"Random Forests\",\"Multi Level Perceptron\"]\n",
    "class_errors = [np.mean(gen_error_lrb),np.mean(gen_error_lrr),np.mean(gen_error_lrl),np.mean(gen_error_lda),\n",
    "                np.mean(gen_error_qda),np.mean(gen_error_knn),np.mean(gen_error_gnb),np.mean(gen_error_svm),\n",
    "                np.mean(gen_error_rf),np.mean(gen_error_nn)]\n",
    "f1_scores_list = [np.mean(f1_lrb),np.mean(f1_lrr),np.mean(f1_lrl),np.mean(f1_lda),np.mean(f1_qda),np.mean(f1_knn),\n",
    "                  np.mean(f1_gnb),np.mean(f1_svm),np.mean(f1_rf),np.mean(f1_nn)]\n",
    "ra_scores_list = [np.mean(ra_lrb),np.mean(ra_lrr),np.mean(ra_lrl),np.mean(ra_lda),np.mean(ra_qda),np.mean(ra_knn),\n",
    "                  np.mean(ra_gnb),np.mean(ra_svm),np.mean(ra_rf),np.mean(ra_nn)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame()\n",
    "model_comparison[\"Models\"] = np.array(models_list)\n",
    "model_comparison[\"Classification_Score\"] = np.array(class_errors)\n",
    "model_comparison[\"F1_Score\"] = np.array(f1_scores_list)\n",
    "model_comparison[\"ROC_AUC_Score\"] = np.array(ra_scores_list)\n",
    "\n",
    "model_comparison['Classification_Score'] = model_comparison.apply(lambda x: round(x['Classification_Score'],3),axis=1)\n",
    "model_comparison['F1_Score'] = model_comparison.apply(lambda x: round(x['F1_Score'],3),axis=1)\n",
    "model_comparison['ROC_AUC_Score'] = model_comparison.apply(lambda x: round(x['ROC_AUC_Score'],3),axis=1)\n",
    "\n",
    "model_comparison.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tabulating the metrics, we can see that QDA has the best performance with our training data in terms of the F1 score and the ROC AUC score. Considering the decision we made earlier about weighing the F1 score and ROC-AUC score higher than the accuracy of the prediction, we will hence consider the QDA model to be the best classifier for our data. We will hence plot the ROC curve and have a look at the performance for different thresholds of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting ROC for QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "qda_gen = QuadraticDiscriminantAnalysis(reg_param=best_c_qda)\n",
    "\n",
    "qda_gen.fit(X,y)\n",
    "\n",
    "y_pred = qda_gen.predict_proba(X)\n",
    "y_pred_actual = qda_gen.predict(X)\n",
    "\n",
    "res = roc_curve(y,y_pred[:,1], drop_intermediate=False)\n",
    "roc_auc = roc_auc_score(y,y_pred_actual)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(res[0], res[1], color='green',\n",
    "        label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - QDA')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the training data and the corresponding ROC curve, we will now run the final component of our modelling, actual assessment on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying QDA Model to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_gen = QuadraticDiscriminantAnalysis(reg_param=best_c_qda)\n",
    "qda_gen.fit(X, y)\n",
    "qda_test_error_score = qda_gen.score(X_test, y_test)\n",
    "y_pred = qda_gen.predict(X_test)\n",
    "qda_test_f1_score = f1_score(y_test,y_pred)\n",
    "qda_test_auc_score = roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "print(\"Test Accuracy Score on QDA: %0.3f\" % qda_test_error_score)\n",
    "print(\"Test F1 Score on QDA: %0.3f\" % qda_test_f1_score)\n",
    "print(\"Test ROC-AUC Score on QDA: %0.3f\" % np.mean(ra_qda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a strong F1 Score and ROC area under curve score, the QDA performance has been benchmarked as the best prediction model currently available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
